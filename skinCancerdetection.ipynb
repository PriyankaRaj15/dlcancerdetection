{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1yDfL_jkTJ5rukfrRgtIfayfR8ZM6UnO8","timestamp":1700040823319}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-jFJJGAhgpCY","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"error","timestamp":1700031400256,"user_tz":-330,"elapsed":421907,"user":{"displayName":"Archana Singh","userId":"11851038882464520148"}},"outputId":"99e8ccef-f747-4a16-b75e-e5f04b077532"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms, models\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.datasets import ImageFolder\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np"],"metadata":{"id":"f88vIEodgwN4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the image transformations\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}"],"metadata":{"id":"zXCLJ7YTgwKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/melanoma_cancer_dataset'\n","image_datasets = {x: ImageFolder(root=data_dir + '/' + x, transform=data_transforms[x])\n","                  for x in ['train', 'test']}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n","              for x in ['train', 'test']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}"],"metadata":{"id":"Zds1zs5FgwHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the VGG19 architecture\n","class VGG19(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super().__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","# Create an instance of the VGG19 model\n","vgg19 = VGG19()"],"metadata":{"id":"rQ_ogze-gwED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use a pre-trained VGG19 model\n","model = models.vgg19()"],"metadata":{"id":"dyM0zC48gwAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modify the last fully connected layer for binary classification\n","model.classifier[6] = nn.Sequential(\n","    nn.Linear(4096, 256),\n","    nn.ReLU(),\n","    nn.Dropout(0.4),\n","    nn.Linear(256, 2),\n","    nn.LogSoftmax(dim=1)\n",")"],"metadata":{"id":"6yaURRqag2xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the loss function and optimizer\n","criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.001)"],"metadata":{"id":"2NGxCTaog2op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the model to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"metadata":{"id":"HDEEEv-9g2lE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","def train_model(model, criterion, optimizer, num_epochs=5):\n","    best_model_wts = model.state_dict()\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        for phase in ['train', 'test']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            if phase == 'test' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = model.state_dict()\n","\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","# Train the model\n","model = train_model(model, criterion, optimizer, num_epochs=5)\n","\n","# Save the trained model\n","torch.save(model, 'model_vgg19.pth')\n"],"metadata":{"id":"fSgmZXD2hSxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yTwjx-hVixWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the image transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","\n","# Load the test dataset\n","test_dataset = ImageFolder('/content/drive/MyDrive/melanoma_cancer_dataset/test', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n","\n","# Load the saved model and move it to the device (CPU or GPU)\n","model = torch.load('model_vgg19.pth')\n","model.to('cuda')  # Move the model to GPU, if available\n","\n","\n","# Define class labels\n","class_labels = ['benign', 'malignant']"],"metadata":{"id":"PwJV5d52j272"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z5sySqO-j245"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4DDY_-puj2zG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix\n","\n","# Create lists to store the ground truth labels and predicted labels\n","true_labels = []\n","predicted_labels = []\n","\n","\n","# Make predictions and collect labels\n","model.eval()\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to('cuda')\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        true_labels.extend(labels.cpu().numpy())\n","        predicted_labels.extend(predicted.cpu().numpy())\n","\n","# Compute the confusion matrix\n","cm = confusion_matrix(true_labels, predicted_labels)\n","\n","# Display the confusion matrix\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"g1w71dDlixPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print images\n","\n","\n","# Define the image transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# Load the test dataset\n","test_dataset = ImageFolder('cell_images/test', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n","\n","# Load the saved model and move it to the device (CPU or GPU)\n","model = torch.load('model_vgg19.pth')\n","model.to('cuda')  # Move the model to GPU, if available\n","\n","# Define class labels\n","class_labels = ['Uninfected', 'Infected']\n","\n","# Display actual and predicted labels for 20 images\n","for images, labels in test_loader:\n","    # Move images to the same device as the model (GPU)\n","    images = images.to('cuda')\n","\n","    with torch.no_grad():\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","    for i in range(len(images)):\n","        # Move the image back to CPU for displaying\n","        image = images[i].cpu()\n","        actual_label = class_labels[labels[i].item()]\n","        predicted_label = class_labels[predicted[i].item()]\n","\n","        plt.imshow(np.transpose(image.numpy(), (1, 2, 0))\n","        plt.title(f'Actual: {actual_label}\\nPredicted: {predicted_label}')\n","        plt.show()\n"],"metadata":{"id":"2vsBgvJ8ixME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4xLGahr75A9f"},"execution_count":null,"outputs":[]}]}